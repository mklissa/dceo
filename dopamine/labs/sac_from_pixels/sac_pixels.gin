# Hyperparameters follow those specified in Table 1 of Appendix D in:
#   "Soft Actor-Critic Algorithms and Applications"
#   by Tuomas Haarnoja et al.
#   https://arxiv.org/abs/1812.05905
# This example gin file runs on PyBullet's HalfCheetahBulletEnv.
import dopamine.continuous_domains.run_experiment
import dopamine.discrete_domains.gym_lib
import dopamine.labs.sac_from_pixels.deepmind_control_lib
import dopamine.labs.sac_from_pixels.continuous_networks
import dopamine.jax.agents.dqn.dqn_agent
import dopamine.jax.agents.sac.sac_agent
import dopamine.replay_memory.circular_replay_buffer

SACAgent.reward_scale_factor = 0.1
SACAgent.network = @continuous_networks.SACConvNetwork
SACAgent.num_layers = 2  # num hidden layers = 2
SACAgent.hidden_units = 1024
SACAgent.gamma = 0.99
SACAgent.update_horizon = 1
SACAgent.min_replay_history = 10000  # agent steps
SACAgent.update_period = 1
SACAgent.target_update_type = 'soft'
SACAgent.target_smoothing_coefficient = 0.005
SACAgent.target_entropy = None  # Defaults to -num_action_dims/2
SACAgent.optimizer = 'adam'
SACAgent.seed = None  # Seed with the current time
SACAgent.stack_size = 3
SACAgent.observation_dtype = %sac_agent.IMAGE_DTYPE
create_optimizer.learning_rate = 3.0e-4
create_optimizer.beta1 = 0.9
create_optimizer.beta2 = 0.999
create_optimizer.eps = 1.0e-8

create_gym_environment.environment_name = 'DM-HalfCheetah'
create_gym_environment.version = 'v2'
create_continuous_runner.schedule = 'continuous_train'
create_continuous_agent.agent_name = 'sac'
deepmind_control_lib.create_deepmind_control_environment.use_image_observations = True
DeepmindControlPreprocessing.action_repeat = 4
ContinuousTrainRunner.create_environment_fn = @gym_lib.create_gym_environment
ContinuousRunner.num_iterations = 3200
ContinuousRunner.training_steps = 1000
ContinuousRunner.evaluation_steps = 1000  # agent steps
ContinuousRunner.max_steps_per_episode = 250
ContinuousRunner.clip_rewards = False

circular_replay_buffer.OutOfGraphReplayBuffer.replay_capacity = 1000000
circular_replay_buffer.OutOfGraphReplayBuffer.batch_size = 256
